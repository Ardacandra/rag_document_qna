# Configuration for the RAG pipeline
LLM_MODEL: "llama3.1:8b"
OLLAMA_BASE_URL: "http://localhost:11434"

# Embedding model (Hugging Face local model)
EMBED_MODEL: "BAAI/bge-small-en-v1.5"

# # Optional keys
# COHERE_API_KEY: ""
# OPENAI_API_KEY: ""

# Paths and index settings
DATA_DIR: "knowledge_base"
CHROMA_PATH: "chroma_db"
COLLECTION_NAME: "advanced_rag_collection"
CHUNK_SIZE: 512
CHUNK_OVERLAP: 20