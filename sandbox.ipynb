{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "37b0dc23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from llama_index.core import Settings\n",
    "from llama_index.llms.ollama import Ollama\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "from llama_index.core.query_engine import RetrieverQueryEngine\n",
    "from llama_index.core.postprocessor import SentenceTransformerRerank"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89ec29c8",
   "metadata": {},
   "source": [
    "### Local LLM Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d31afc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57b18be5d16347cfb4272d4e2cf118aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4bb4caaede7748ae8debbbba0d20c9db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "326366bb5a0042e1a31aa48dc761b89b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f63ffa5cce3943f2b6218fb5fd6699fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/52.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14bafb684384446f9f0b7ce5c371a554",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/743 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91b905c4ea7a4a999bc9dae20d71ef9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/133M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0aa638e487aa4ada845f028ddba3d434",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/366 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f1d38c9c6dd4959b17731ff40983e70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dca1e4d0c41c4b50a2966e12fe2c679d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49ea0ee7e8be4ea5a8b358cfeb048b90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c75bd0759f84bd3aa2e0782441d2406",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM set to: llama3.1:8b (via Ollama)\n",
      "Embedding Model set to: BAAI/bge-small-en-v1.5 (Hugging Face)\n"
     ]
    }
   ],
   "source": [
    "# 1. Configure the Local LLM (The answer generator)\n",
    "# This model name must match the one you downloaded with 'ollama run <model_name>'\n",
    "local_llm = Ollama(\n",
    "    model=\"llama3.1:8b\", \n",
    "    base_url=\"http://localhost:11434\", \n",
    "    request_timeout=120.0  # Increase timeout for slow local inference\n",
    ")\n",
    "\n",
    "# 2. Configure the Local Embedding Model (The knowledge indexer/retriever)\n",
    "# BGE-small is the standard choice for excellent performance on a local machine.\n",
    "local_embed_model = HuggingFaceEmbedding(\n",
    "    model_name=\"BAAI/bge-small-en-v1.5\"\n",
    ")\n",
    "\n",
    "# 3. Apply the settings globally\n",
    "# LlamaIndex will automatically use these components for all indexing and querying.\n",
    "Settings.llm = local_llm\n",
    "Settings.embed_model = local_embed_model\n",
    "\n",
    "print(f\"LLM set to: {Settings.llm.model} (via Ollama)\")\n",
    "print(f\"Embedding Model set to: {Settings.embed_model.model_name} (Hugging Face)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b92be4d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d686f2e536ee4fe28d8bcbd24f958bd9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/794 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1246735a7fae4758b0cd264ae127a773",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "377c2d2e1ece4b1aba9cf08441ec9a48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5da4cf5e2b647259d700b1421fde470",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53174cb879254ec7842d8b8cdaa359d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54692d89342d42bd89e00b095151d116",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/132 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06bc33c8381b4c20a86a4ef308682147",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Open-source Reranker configured.\n"
     ]
    }
   ],
   "source": [
    "# Initialize the Open-Source Reranker\n",
    "# This model runs locally using the Hugging Face Transformers library.\n",
    "local_reranker = SentenceTransformerRerank(\n",
    "    model=\"cross-encoder/ms-marco-MiniLM-L-6-v2\", # A small, fast, highly effective reranker\n",
    "    top_n=5 # The final number of chunks passed to the LLM\n",
    ")\n",
    "print(\"Open-source Reranker configured.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6c0d5469",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # In the query engine creation (Phase 2, Step 4), ensure you use the new object:\n",
    "# query_engine = RetrieverQueryEngine(\n",
    "#     retriever=retriever,\n",
    "#     node_postprocessors=[local_reranker], # <-- Use the local reranker object\n",
    "#     llm=local_llm # <-- LLM is already set by Settings.llm, but good to be explicit\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "824df0cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# query_str = \"What is the motto of France and when was the Eiffel Tower finished?\"\n",
    "\n",
    "# response = query_engine.query(query_str)\n",
    "\n",
    "# # Display the results\n",
    "# print(\"\\n--- Final RAG Answer ---\")\n",
    "# print(response.response)\n",
    "\n",
    "# print(\"\\n--- Source Chunks Used ---\")\n",
    "# # The source nodes are the actual text chunks retrieved and passed to the LLM\n",
    "# for node in response.source_nodes:\n",
    "#     print(f\"* Score: {node.score:.4f}\")\n",
    "#     print(f\"  Text: {node.text[:80]}...\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ad4c50",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag_document_qna",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
